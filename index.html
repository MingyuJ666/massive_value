<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=2">
  <title>Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/disk.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://mingyuj666.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/MingyuJ666/The-Impact-of-Reasoning-Step-Length-on-Large-Language-Models">
            The Impact of Reasoning Step Length on Large Language Models
          </a>
          <a class="navbar-item" href="https://tiuxuxsh76075.github.io/prollm.github.io/">
            ProLLM: Protein Chain-of-Thoughts Enhanced LLM for Protein-Protein Interaction Prediction
          </a>
          <a class="navbar-item" href="https://luckfort.github.io/explore_CD/">
            Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://mingyuj666.github.io/">Mingyu Jin</a><sup>1</sup>,</span>
            <span class="author-block">
               Kai Mei</a><sup>1</sup>,</span>
              <a href="https://wujiangxu.github.io/">Wujiang Xu</a><sup>1</sup>,</span>
              <a href="https://eric-mingjie.github.io/">Mingjie Sun</a><sup>2</sup>,</span>
              <a href="https://www.ruixiangtang.net/home">Ruixiang Tang</a><sup>1</sup>,</span>
              <a href="https://mengnandu.com/">Mengnan Du</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="https://zirui-ray-liu.github.io/">Zirui Liu</a><sup>3</sup></span>
              <a href="https://yongfeng.me/">Yongfeng Zhang</a><sup>1</sup></span>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>1</sup>Rutgers University,</span>
            <span class="author-block"><sup>2</sup>Carnegie Mellon University,</span>
            <span class="author-block"><sup>3</sup>University of Minnesota,</span>
            <span class="author-block"><sup>4</sup>New Jersey Institute of Technology,</span>
          </div>
          
         

          <div class="is-size-5 publication-authors">
            <span class="author-block"><b>Accepted by ICML 2025</b></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2502.01563"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <img src="./static/images/icml.png" alt="Accepted by ICML" style="width: 40px; height: 16px;"> <!-- ‰øÆÊîπÂõæÁâáÈ´òÂ∫¶ -->
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/MingyuJ666/Rope_with_LLM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="main image">
  <style type="text/css">
    body{
      background: no-repeat center center fixed;
                  -webkit-background-size: cover;
                  -o-background-size: cover;                
                  background-size: cover;
    }
  </style>

  <div class="image-body">
    <div align=center>
      <img src="./static/images/Figure1.png" alt="Introduction" style="width: 33%;">
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-fifths">
          <h2 class="subtitle has-text-centered">
            <h4 class="title is-6" align="center"> In transformer-based Large Language Models with RoPE(like Llama, Gemma), the attention queries (Q) and keys (K) exhibit concentrated massive values in certain dimensions.
          </h2>
        </div>
      </div>
    </div>
  </div>

  <br /> <br />

  <div class="image-body">
    <div align=center>
      <img src="./static/images/Figure2.png" alt="Introduction" style="width: 58%;">
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-fifths">
          <h2 class="subtitle has-text-centered">
            <h4 class="title is-6" align="center"> Q and K Embedding Vector in Llama-2-7B, we choose Layer 10 and 20. This visualization shown here is a two-dimensional image because we averaged over the sequence-length dimension. The horizontal axis is the number of heads, and the vertical axis is head dim. We can see that the massive value is concentrated at the bottom of the picture.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Large language models (LLMs) have achieved remarkable success in contextual knowledge understanding. In this paper, we show for the first time that these concentrated massive values consistently emerge in specific regions of attention queries (Q) and keys (K) while not having such patterns in values (V) in various modern transformer-based LLMs. Through extensive experiments, we further demonstrate that these massive values play a critical role in interpreting contextual knowledge (i.e., knowledge obtained from the current context window) rather than in retrieving parametric knowledge stored within the model‚Äôs parameters. Our further investigation of quantization strategies reveals that ignoring these massive values leads to a pronounced drop in performance on tasks requiring rich contextual understanding, aligning with our analysis. Finally, we trace the emergence of concentrated massive values and find that such concentration is caused by Rotary Positional Encoding (RoPE) and it appears since very first layers. These findings shed new light on how Q and K operate in LLMs and offer practical insights for model design and optimization. 
            </a>
          </p>
          
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>


  <br /> <br />


  <!--Main Body-->

  <div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">üîç Key Findings</h2>

    <div class="content has-text-justified">
      <p align="center">We highlight three core findings from our study of massive values in LLM attention mechanisms.</p>

      <h4 class="title is-5" align="center">üìä Functional Role of Massive Values</h4>
      <p align="center">
        We conduct extensive experiments that show that massive values in <code>Q</code> and <code>K</code> matrices play a crucial role in contextual knowledge retrieval, while having a limited effect on parametric knowledge.
      </p>

      <h4 class="title is-5" align="center">‚öôÔ∏è Impact on Quantization</h4>
      <p align="center">
        We evaluate 3 quantization strategies and find that methods explicitly addressing massive values better preserve contextual understanding. This suggests the need for quantization-aware designs.
      </p>

      <h4 class="title is-5" align="center">‚è±Ô∏è Temporal Origin Analysis</h4>
      <p align="center">
        Through causal and temporal analysis, we show that massive values originate from the RoPE mechanism and appear as early as the initial layers. 
      </p>
    </div>
  </div>
</div>



 

  <!-- Experiment. -->
    
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">üìäExperiments</h2>
      
        <div class="content has-text-justified">
          <h5 class="title is-5" align="center">üìà Massive Values Contribute to Contextual Knowledge Understanding</h5>
          
          <p>
            As shown in <b>Table 1</b>, <i>Parametric Knowledge Retrieval</i> tasks still maintain <i>relatively high accuracy</i> even when massive values are disrupted, showing degradation of only 15‚Äì20%. However, for <i>Contextual Knowledge Understanding</i> tasks, massive values play a <b>crucial role</b> in preserving performance.
          </p>
        
          <p>
            For example, Cities tasks maintain strong performance (76‚Äì88%), while Technology and Celebrity tasks remain above 70%. In contrast, disrupting <i>non-massive values</i> causes less than 1% performance drop, highlighting the specificity of massive values' role.
          </p>
        
          <p>
            On reasoning tasks like <b>GSM8K</b>, accuracy drops are dramatic (e.g., <i>Gemma2-9B</i>: 81.3% ‚Üí 15.1%), and Passkey tasks collapse from 100% to near-zero accuracy (0‚Äì2%). IMDB sentiment accuracy also drops from 94% to single digits. This emphasizes the importance of massive values in preserving contextual reasoning ability.
          </p>
        
          <h6 class="title is-6">üß™ PPL and Diversity Score</h6>
          <p>
            In addition to accuracy, we assess the models with <b>perplexity (PPL)</b> and <b>diversity</b> as complementary metrics. Lower PPL suggests better modeling confidence, while higher 2-gram diversity indicates richer output. Both metrics support the same conclusion: <b>massive values are essential for contextual understanding</b>.
          </p>
        </div>

        <div class="image-body">
          <div align=center>
            <img src="./static/images/Fig3.png" alt="CD Introduction" style="width: 70%;">
            <div class="columns is-centered has-text-centered">
              <div class="column is-three-fifths">
                <h2 class="subtitle has-text-centered">
                
                </h2>
              </div>
            </div>
          </div>
        </div>

  <br /> <br />
  
 <div class="content has-text-justified">
  <h5 class="title is-5" align="center">üìâ Massive Values & Quantization</h5>

  <p>
    We evaluate three quantization methods ‚Äî <b>AWQ</b>, <b>SmoothQuant</b>, and <b>GPTQ</b> ‚Äî to test how well they preserve <i>massive values</i>.
  </p>

  <p>
    AWQ and SmoothQuant explicitly preserve massive values and maintain strong performance across all tasks. In contrast, GPTQ, which doesn‚Äôt, suffers major accuracy drops on reasoning tasks like GSM8K and AQUA.
  </p>

  <p>
    This gap confirms that <b>preserving massive values is key to contextual understanding</b>. Without it, models struggle in complex reasoning.
  </p>
</div>
      
  <div class="image-body">
    <div align=center>
      <img src="./static/images/Fig4.png" alt="CD Introduction" style="width: 100%;">
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-fifths">
          <h2 class="subtitle has-text-centered">
            <h4 class="title is-6" align="center"> Impacts of different quantization methods on Llama3-8b across different benchmarks.
          </h2>
        </div>
      </div>
    </div>
  </div>

  <br /> <br />
      
  <div class="image-body">
    <div align=center>
      <img src="./static/images/converge.png" alt="CD Introduction" style="width: 100%;">
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-fifths">
          <h2 class="subtitle has-text-centered">
            The converging point of each dataset on Gemma, LLaMA, and Qwen represented by the percent depth proportion.
          </h2>
        </div>
      </div>
    </div>
  </div>

  <br /> <br />
      
      <div class="content has-text-justified">

        <p><b>RQ3: Do LLMs' Concept Depth of the same size behave consistently?</b></p>
        <p>
          With the same number of model parameters, the models generally have a comparable understanding of the datasets.
        </p>
        
        
      </div>
    
      <div class="image-body">
        <div align=center>
          <img src="./static/images/rq3.jpg" alt="CD Introduction" style="width: 70%;">
          <div class="columns is-centered has-text-centered">
            <div class="column is-three-fifths">
              <h2 class="subtitle has-text-centered">
                Linear probing accuracy of Gemma-7B, LLaMA-7B, Qwen-7B on nine datasets.
              </h2>
            </div>
          </div>
        </div>
      </div>
      
      <br/><br/>

      <div class="content has-text-justified">

        <p><b>Ablation Study: How can quantization (lower model precision) and noises (examing the robustness) affect LLM's Concept Depths?</b></p>
        <p>
          Noises or 8-bit-quantization can cause the accuracy to converge more slowly. Compressing the LLMs to 16 bits doesn't harm the understanding process too much.
The layer-wise representations of LLMs are susceptible to noise and high-ratio quantization. Therefore, it is crucial to proceed cautiously when conducting high-ratio quantization inference.
        </p>
        
      </div>

    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Conclusion. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Conclusion</h2>
        <div class="content has-text-justified">
          Our study provides novel insights into the role and origin of massive values in Large Language Models (LLMs). Through systematic investigation, we find that massive values are critical in contextual knowledge understanding tasks, such as passkey retrieval and IMDB sentiment understanding. In contrast, their influence on parametric knowledge retrieval tasks, such as world knowledge retrieval, is limited. This finding emphasizes the importance of preserving massive value to maintain model performance in reasoning and context-dependent tasks. Our investigation reveals that RoPE induces massive value stripes, distinct patterns exclusively in the Q and K, while absent in models without RoPE, such as OPT. This highlights how positional encoding mechanisms contribute to massive values, particularly low-frequency channel dimensions, offering new insights into RoPE's role in LLMs. This study establishes a deeper understanding of massive values in LLMs, their critical role in contextual knowledge understanding, their implications for model optimization techniques such as quantization, and their connection to RoPE-induced patterns. These findings lay the foundation for developing more robust, efficient, and interpretable LLM architectures and optimization strategies.
          
        </div>
      </div>
    </div>
    <!--/ Conclusion. -->
  </div>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{jin2025massive,
  title={Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding},
  author={Jin, Mingyu and Mei, Kai and Xu, Wujiang and Sun, Mingjie and Tang, Ruixiang and Du, Mengnan and Liu, Zirui and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2502.01563},
  year={2025}
}</code></pre>
  </div>
</section>




</body>
</html>
